# atmaCup15_14thSolution

- 14th place solution for [atmaCup15](https://www.guruguru.science/competitions/21)
- Ensemble CatBoost(regression), LightGBM(regression), XGBoost(multiclass), SVDpp and KNNBaseline with Nelder-Mead
- This is a recommender system competition, so the graph(Node2Vec) features or factorization machine embeddings are so important.
- I used [kagglib](https://github.com/shu421/kagglib), my own library, for feature engineering. Thanks to this, the feature engineering is simpler, more readable, and easier to maintain.
- More detailed solution: https://www.guruguru.science/competitions/21/discussions/979f7ced-2aaf-492c-a2c7-18549f7d16c3/
